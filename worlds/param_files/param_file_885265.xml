<?xml version="1.0"?>
<opencv_storage>
<rand_seed>885265</rand_seed>
<c_time>0.</c_time>
<dt>1.</dt>
<end_time>10000.</end_time>
<map_height>100.</map_height>
<map_widht>100.</map_widht>
<n_nodes>20</n_nodes>
<k_map_connections>5</k_map_connections>
<k_connection_radius>500.</k_connection_radius>
<p_connect>1.</p_connect>
<p_obstacle_on_edge>2.0000000000000001e-01</p_obstacle_on_edge>
<p_blocked_edge>5.0000000000000003e-02</p_blocked_edge>
<p_pay_obstacle_cost>0.</p_pay_obstacle_cost>
<n_task_types>4</n_task_types>
<flat_tasks>1</flat_tasks>
<p_task_initially_active>4.0000000000000002e-01</p_task_initially_active>
<p_impossible_task>0.</p_impossible_task>
<p_active_task>0.</p_active_task>
<min_task_time>1000.</min_task_time>
<max_task_time>6000.</max_task_time>
<min_task_work>1.</min_task_work>
<max_task_work>1.</max_task_work>
<min_task_reward>100.</min_task_reward>
<max_task_reward>500.</max_task_reward>
<n_agents>2</n_agents>
<n_agent_types>1</n_agent_types>
<min_travel_vel>2.2999999999999998e+00</min_travel_vel>
<max_travel_vel>2.7000000000000002e+00</max_travel_vel>
<min_agent_work>100.</min_agent_work>
<max_agent_work>100.</max_agent_work>
</opencv_storage>
